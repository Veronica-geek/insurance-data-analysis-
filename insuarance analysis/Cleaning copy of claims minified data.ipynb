{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a19f77df-6dc7-4fc9-b795-7c02660fcef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data loaded: 1039 rows, 42 columns\n",
      "Duplicates removed: 0\n",
      "\n",
      "Cleaning complete! Cleaned data saved to: fully_cleaned_claims_data.csv\n",
      "Final shape: 1039 rows, 42 columns\n",
      "\n",
      "First 5 rows:\n",
      "  REGISTRATION_DATE KC_REPUDIATE_DT  DRIVER_AGE  KC_OUTSTANDING_RESERVE  \\\n",
      "0        2025-01-06             NaT        31.0                       0   \n",
      "1        2024-11-29             NaT        31.0                     700   \n",
      "2        2025-03-21             NaT        31.0                  120700   \n",
      "3        2024-12-13             NaT        31.0                       0   \n",
      "4        2025-02-24             NaT        31.0                   80200   \n",
      "\n",
      "   TIME_TAKEN_REGISTRATION  KC_STATUS      KC_STATUS_TEXT POLICY_NUMBER  \\\n",
      "0                        1         74  Authorized Payment   G/HQS/00001   \n",
      "1                        1          2           Inprocess   G/HQS/00002   \n",
      "2                        1          5           Inprocess   G/EMB/00003   \n",
      "3                        1          2           Inprocess   G/HGS/00004   \n",
      "4                        1          5           Inprocess   G/HGS/00004   \n",
      "\n",
      "   CLAIMNUMBER RISKNAME  ... MANUFACTURING_YEAR POLICY_HOLDER_GENDER  \\\n",
      "0  C/HQS/00001  KD00001  ...               2014                 Male   \n",
      "1  C/HQS/00002  KB00002  ...               2002                 Male   \n",
      "2  C/EMB/00003  KB00003  ...               2007                  NaN   \n",
      "3  C/HGS/00004  KC00004  ...               2013                 Male   \n",
      "4  C/HGS/00006  KC00004  ...               2013                 Male   \n",
      "\n",
      "  POLICY_HOLDER_AGE KC_FIRST_REPUDIATE_REM KC_FIRST_REPUDIATE_REM_DATA  \\\n",
      "0              35.0         No Repudiation              No Repudiation   \n",
      "1              25.0         No Repudiation              No Repudiation   \n",
      "2              25.0         No Repudiation              No Repudiation   \n",
      "3              66.0         No Repudiation              No Repudiation   \n",
      "4              66.0         No Repudiation              No Repudiation   \n",
      "\n",
      "   KC_SECOND_REPUDIATE_REM KC_FIFTH_REPUDIATE_REM Date_Reported Quarter  Year  \n",
      "0           No Repudiation         No Repudiation    2025-01-06  2025Q1  2025  \n",
      "1           No Repudiation         No Repudiation    2024-11-29  2024Q4  2024  \n",
      "2           No Repudiation         No Repudiation    2025-03-21  2025Q1  2025  \n",
      "3           No Repudiation         No Repudiation    2024-12-13  2024Q4  2024  \n",
      "4           No Repudiation         No Repudiation    2025-02-24  2025Q1  2025  \n",
      "\n",
      "[5 rows x 42 columns]\n",
      "\n",
      "Missing values summary:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_13252\\1238469881.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(df[col], errors='coerce', dayfirst=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_13252\\1238469881.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(df[col], errors='coerce', dayfirst=True)\n",
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_13252\\1238469881.py:39: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  parsed = pd.to_datetime(df[col], errors='coerce', dayfirst=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KC_REPUDIATE_DT         1002\n",
      "PERILNAME                  1\n",
      "GCT_NAME                   3\n",
      "MAKE_NAME                106\n",
      "MODEL_NAME               106\n",
      "POLICY_HOLDER_GENDER     209\n",
      "dtype: int64\n",
      "\n",
      "Date columns info:\n",
      "  REGISTRATION_DATE NOTIFICATION_DATE  DATE_LOSS Date_Reported Quarter\n",
      "0        2025-01-06        2025-01-06 2024-12-24    2025-01-06  2025Q1\n",
      "1        2024-11-29        2024-11-29 2024-08-22    2024-11-29  2024Q4\n",
      "2        2025-03-21        2025-03-21 2024-02-28    2025-03-21  2025Q1\n",
      "3        2024-12-13        2024-12-13 2023-05-02    2024-12-13  2024Q4\n",
      "4        2025-02-24        2025-02-24 2023-06-26    2025-02-24  2025Q1\n",
      "5        2025-03-19        2025-03-19 2024-02-17    2025-03-19  2025Q1\n",
      "6        2025-02-05        2025-02-05 2022-02-12    2025-02-05  2025Q1\n",
      "7        2025-02-21        2025-02-21 2022-08-29    2025-02-21  2025Q1\n",
      "8        2025-01-31        2025-01-31 2024-09-18    2025-01-31  2025Q1\n",
      "9        2025-03-12        2025-03-12 2023-09-23    2025-03-12  2025Q1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='pandas')\n",
    "\n",
    "file_path = 'Copy of Claims Minified Data.xlsx' \n",
    "df = pd.read_excel(file_path, sheet_name='Sheet4', engine='openpyxl')\n",
    "\n",
    "print(f\"Original data loaded: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "\n",
    "# = 2. Clean column names \n",
    "df.columns = df.columns.str.strip().str.replace('##', '')\n",
    "\n",
    "#  3. Handle missing values \n",
    "df = df.replace(['N/A', '', 'NA'], np.nan)\n",
    "\n",
    "# =4. Parse all date columns =\n",
    "date_cols = ['REGISTRATION_DATE', 'KC_REPUDIATE_DT', 'NOTIFICATE_DATE', \n",
    "             'DATE_LOSS', 'NOTIFICATION_DATE', 'COVER_START_DATE', 'COVER_END_DATE']\n",
    "\n",
    "common_formats = ['%d-%b-%Y', '%d-%B-%Y', '%d-%m-%Y', '%Y-%m-%d', '%d/%m/%Y']\n",
    "\n",
    "for col in date_cols:\n",
    "    if col in df.columns:\n",
    "        parsed = pd.Series([pd.NaT] * len(df))  \n",
    "        success = False\n",
    "        for fmt in common_formats:\n",
    "            try:\n",
    "                # Adjust dayfirst based on format\n",
    "                dayfirst = '%' not in fmt.split('-')[0]  \n",
    "                temp = pd.to_datetime(df[col], format=fmt, errors='raise', dayfirst=dayfirst)\n",
    "                parsed = temp\n",
    "                success = True\n",
    "                break\n",
    "            except:\n",
    "                continue\n",
    "        if not success:\n",
    "            \n",
    "            parsed = pd.to_datetime(df[col], errors='coerce', dayfirst=True)\n",
    "        df[col] = parsed\n",
    "        \n",
    "# = 5. Clean numeric columns \n",
    "numeric_cols = ['DRIVER_AGE', 'KC_OUTSTANDING_RESERVE', 'TIME_TAKEN_REGISTRATION',\n",
    "                'KC_STATUS', 'KC_SUM_INSURED', 'MANUFACTURING_YEAR', 'POLICY_HOLDER_AGE']\n",
    "\n",
    "for col in numeric_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col].astype(str).str.replace(',', ''), errors='coerce')\n",
    "\n",
    "# = 6. Fix age anomalies (negative or zero) \n",
    "age_cols = ['DRIVER_AGE', 'POLICY_HOLDER_AGE']\n",
    "for col in age_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].where(df[col] > 0, np.nan)\n",
    "        median_age = df[col].median()\n",
    "        df[col] = df[col].fillna(median_age)\n",
    "\n",
    "# Impute MANUFACTURING_YEAR with median if needed\n",
    "if 'MANUFACTURING_YEAR' in df.columns:\n",
    "    df['MANUFACTURING_YEAR'] = df['MANUFACTURING_YEAR'].fillna(df['MANUFACTURING_YEAR'].median())\n",
    "\n",
    "# = 7. Clean categorical columns =\n",
    "cat_cols = ['KC_STATUS_TEXT', 'POLICE_REPORTED', 'PERILNAME', 'IC_NAME', 'GP_NAME',\n",
    "            'GCT_NAME', 'INT_TYP', 'BR_NAME', 'MAKE_NAME', 'MODEL_NAME',\n",
    "            'POLICY_HOLDER_GENDER', 'POLICE_STATION_NAME']\n",
    "\n",
    "for col in cat_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(str).str.strip().str.title()\n",
    "        df[col] = df[col].replace(['Nan', 'Na'], np.nan)\n",
    "\n",
    "# Special handling\n",
    "df['POLICE_STATION_NAME'] = df['POLICE_STATION_NAME'].fillna('Unknown')\n",
    "df['POLICE_REPORTED'] = df['POLICE_REPORTED'].replace({np.nan: 'No', 'Yes': 'Yes', 'No': 'No'})\n",
    "\n",
    "# ==================== 8. Repudiation remarks ===\n",
    "repud_cols = ['KC_FIRST_REPUDIATE_REM', 'KC_FIRST_REPUDIATE_REM_DATA',\n",
    "              'KC_SECOND_REPUDIATE_REM', 'KC_FIFTH_REPUDIATE_REM']\n",
    "for col in repud_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].fillna('No Repudiation')\n",
    "\n",
    "# ==================== 9. Drop duplicates ====================\n",
    "initial_rows = df.shape[0]\n",
    "df = df.drop_duplicates(subset=['CLAIMNUMBER'], keep='first')\n",
    "print(f\"Duplicates removed: {initial_rows - df.shape[0]}\")\n",
    "\n",
    "# ==================== 10. Final touches ====================\n",
    "# Ensure ID columns are strings\n",
    "id_cols = ['POLICY_NUMBER', 'CLAIMNUMBER', 'CLIENT_MOBILE_NUMBER', 'INTERMEDIARY_PHONE_NO']\n",
    "for col in id_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(str)\n",
    "\n",
    "# Drop completely empty columns if any\n",
    "df = df.dropna(axis=1, how='all')\n",
    "\n",
    "# ==================== 11. Add analysis-ready columns ====================\n",
    "df['Date_Reported'] = df['NOTIFICATION_DATE']  # Best proxy for when claim was reported\n",
    "df['Quarter'] = df['Date_Reported'].dt.to_period('Q').astype(str)\n",
    "df['Year'] = df['Date_Reported'].dt.year\n",
    "\n",
    "# ==================== 12. Save cleaned file ====================\n",
    "output_file = 'fully_cleaned_claims_data.csv'\n",
    "df.to_csv(output_file, index=False)\n",
    "print(f\"\\nCleaning complete! Cleaned data saved to: {output_file}\")\n",
    "print(f\"Final shape: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "\n",
    "# ==================== 13. Quick overview ====================\n",
    "print(\"\\nFirst 5 rows:\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nMissing values summary:\")\n",
    "print(df.isnull().sum()[df.isnull().sum() > 0])\n",
    "\n",
    "print(\"\\nDate columns info:\")\n",
    "print(df[['REGISTRATION_DATE', 'NOTIFICATION_DATE', 'DATE_LOSS', 'Date_Reported', 'Quarter']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "661422cc-fa7f-4411-a850-b2034b4f3ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel('fully_cleaned_claims_data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4099ce-a3ed-4a0d-91a0-7d365f0dbed3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
